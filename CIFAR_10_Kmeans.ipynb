{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vioritiva\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Training accuracy: 0.22126\n",
      "Test accuracy: 0.2219\n",
      "Training NMI: 0.07292053100720179\n",
      "Test NMI: 0.07538402608447203\n",
      "Training silhouette score: 0.050634543919521095\n",
      "Test silhouette score: 0.0491361564139692\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score, silhouette_score\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "X_train_scaled = X_train/255\n",
    "X_test_scaled = X_test/255\n",
    "\n",
    "# Define number of clusters\n",
    "n_clusters = 10\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "kmeans.fit(X_train_scaled)\n",
    "\n",
    "# Get labels for training and test data\n",
    "y_pred = kmeans.predict(X_train_scaled)\n",
    "y_pred_test = kmeans.predict(X_test_scaled)\n",
    "\n",
    "# Creating a Mapping Between Predicted Labels and Clusters Based on Majority Labels within Each Cluster\n",
    "relation = dict((i, 0) for i in range(n_clusters))\n",
    "for i in range(n_clusters):\n",
    "    u, indeces = np.unique(y_train[y_pred == i], return_inverse=True)\n",
    "    i_pred = u[np.argmax(np.bincount(indeces))]\n",
    "    relation[i] = i_pred\n",
    "\n",
    "y_pred_corr = np.array([relation[i] for i in y_pred])\n",
    "\n",
    "# Creating a Mapping Between Predicted Labels and Clusters Based on Majority Labels within Each Cluster\n",
    "relation_test = dict((i, 0) for i in range(n_clusters))\n",
    "for i in range(n_clusters):\n",
    "    u, indeces = np.unique(y_test[y_pred_test == i], return_inverse=True)\n",
    "    i_pred = u[np.argmax(np.bincount(indeces))]\n",
    "    relation_test[i] = i_pred\n",
    "\n",
    "y_pred_corr_test = np.array([relation_test[i] for i in y_pred_test])\n",
    "\n",
    "# Compute accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_corr)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_corr_test)\n",
    "\n",
    "# Compute NMI\n",
    "nmi_train = normalized_mutual_info_score(y_train.flatten(), y_pred_corr)\n",
    "nmi_test = normalized_mutual_info_score(y_test.flatten(), y_pred_corr_test)\n",
    "\n",
    "# Compute silhouette score\n",
    "silhouette_train = silhouette_score(X_train_scaled, y_pred)\n",
    "silhouette_test = silhouette_score(X_test_scaled, y_pred_test)\n",
    "\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Training NMI:\", nmi_train)\n",
    "print(\"Test NMI:\", nmi_test)\n",
    "print(\"Training silhouette score:\", silhouette_train)\n",
    "print(\"Test silhouette score:\", silhouette_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
